import pandas as pd
from selenium import webdriver
from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException
import time
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException

def get_jobs(keyword, num_jobs, verbose, path, slp_time):

    '''Gathers jobs as a dataframe, scraped from Glassdoor'''

    #Initializing the webdriver
    options = webdriver.ChromeOptions()

    #Uncomment the line below if you'd like to scrape without a new Chrome window every time.
    #options.add_argument('headless')

    # Change the path to where chromedriver is in your home folder.
    s = Service(path)
    driver = webdriver.Chrome(service=s, options=options)
    driver.set_window_size(1120, 1000)

    url = "https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword="+keyword+"&sc.keyword="+keyword+"&locT=&locId=&jobType="
    #url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword="' + keyword + '"&locT=C&locId=1147401&locKeyword=San%20Francisco,%20CA&jobType=all&fromAge=-1&minSalary=0&includeNoSalaryJobs=true&radius=100&cityId=-1&minRating=0.0&industryId=-1&sgocId=-1&seniorityType=all&companyId=-1&employerSizes=0&applicationType=0&remoteWorkType=0'
    driver.get(url)
    jobs = []

    while len(jobs) < num_jobs:  #If true, should be still looking for new jobs.

        #Let the page load. Change this number based on your internet speed.
        #Or, wait until the webpage is loaded, instead of hardcoding it.
        time.sleep(slp_time)

        #Test for the "Sign Up" prompt and get rid of it.
        try:
            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, "selected"))).click()
        except NoSuchElementException:
            print("Element with class 'selected' not found.")
            pass

        time.sleep(.1)

        try:
            driver.find_element_by_css_selector('[alt="Close"]').click() #clicking to the X.
            print(' x out worked')
        except NoSuchElementException:
            print(' x out failed')
            pass


        #Going through each job in this page
        job_buttons = driver.find_element(By.CLASS_NAME,"jl") #jl for Job Listing. These are the buttons we're going to click.
        for job_button in job_buttons:  

            print("Progress: {}".format("" + str(len(jobs)) + "/" + str(num_jobs)))
            if len(jobs) >= num_jobs:
                break
            try:
                job_button.click()  #You might 
                time.sleep(1)
                collected_successfully = False
            except:
                continue
            while not collected_successfully:
                try:
                    company_name = driver.find_element_by_xpath('.//div[@class="employerName"]').text
                    location = driver.find_element_by_xpath('.//div[@class="location"]').text
                    job_title = driver.find_element_by_xpath('.//div[contains(@class, "title")]').text
                    job_description = driver.find_element_by_xpath('.//div[@class="jobDescriptionContent desc"]').text
                    collected_successfully = True
                except:
                    time.sleep(5)

            try:
                salary_estimate = driver.find_element_by_xpath('.//span[@class="gray salary"]').text
            except NoSuchElementException:
                salary_estimate = -1 #You need to set a "not found value. It's important."

            try:
                rating = driver.find_element_by_xpath('.//span[@class="rating"]').text
            except NoSuchElementException:
                rating = -1 #You need to set a "not found value. It's important."

            #Printing for debugging
            if verbose:
                print("Job Title: {}".format(job_title))
                print("Salary Estimate: {}".format(salary_estimate))
                print("Job Description: {}".format(job_description[:500]))
                print("Rating: {}".format(rating))
                print("Company Name: {}".format(company_name))
                print("Location: {}".format(location))

            #Going to the Company tab...
            #clicking on this:
            #<div class="tab" data-tab-type="overview"><span>Company</span></div>
            try:
                driver.find_element_by_xpath('.//div[@class="tab" and @data-tab-type="overview"]').click()

                try:
                    #<div class="infoEntity">
                    #    <label>Headquarters</label>
                    #    <span class="value">San Francisco, CA</span>
                    #</div>
                    headquarters = driver.find_element_by_xpath('.//div[@class="infoEntity"]//label[text()="Headquarters"]//following-sibling::*').text
                except NoSuchElementException:
                    headquarters = -1

                try:
                    size = driver.find_element_by_xpath('.//div[@class="infoEntity"]//label[text()="Size"]//following-sibling::*').text
                except NoSuchElementException:
                    size = -1

                try:
                    founded = driver.find_element_by_xpath('.//div[@class="infoEntity"]//label[text()="Founded"]//following-sibling::*').text
                except NoSuchElementException:
                    founded = -1

                try:
                    type_of_ownership = driver.find_element_by_xpath('.//div[@class="infoEntity"]//label[text()="Type"]//following-sibling::*').text
                except NoSuchElementException:
                    type_of_ownership = -1

                try:
                    industry = driver.find_element_by_xpath('.//div[@class="infoEntity"]//label[text()="Industry"]//following-sibling::*').text
                except NoSuchElementException:
                    industry = -1

                try:
                    sector = driver.find_element_by_xpath('.//div[@class="infoEntity"]//label[text()="Sector"]//following-sibling::*').text
                except NoSuchElementException:
                    sector = -1

                try:
                    revenue = driver.find_element_by_xpath('.//div[@class="infoEntity"]//label[text()="Revenue"]//following-sibling::*').text
                except NoSuchElementException:
                    revenue = -1

                try:
                    competitors = driver.find_element_by_xpath('.//div[@class="infoEntity"]//label[text()="Competitors"]//following-sibling::*').text
                except NoSuchElementException:
                    competitors = -1

            except NoSuchElementException:  #Rarely, some job postings do not have the "Company" tab.
                headquarters = -1
                size = -1
                founded = -1
                type_of_ownership = -1
                industry = -1
                sector = -1
                revenue = -1
                competitors = -1


            if verbose:
                print("Headquarters: {}".format(headquarters))
                print("Size: {}".format(size))
                print("Founded: {}".format(founded))
                print("Type of Ownership: {}".format(type_of_ownership))
                print("Industry: {}".format(industry))
                print("Sector: {}".format(sector))
                print("Revenue: {}".format(revenue))
                print("Competitors: {}".format(competitors))
                print("@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@")

            jobs.append({"Job Title" : job_title,
            "Salary Estimate" : salary_estimate,
            "Job Description" : job_description,
            "Rating" : rating,
            "Company Name" : company_name,
            "Location" : location,
            "Headquarters" : headquarters,
            "Size" : size,
            "Founded" : founded,
            "Type of ownership" : type_of_ownership,
            "Industry" : industry,
            "Sector" : sector,
            "Revenue" : revenue,
            "Competitors" : competitors})
            #add job to jobs


        #Clicking on the "next page" button
        try:
            page = driver.find_element_by_xpath('.//div[@class="tbl fill padHorz margVert"]').text
            page = page.split()
            if page[1]==page[3]:
                break
            driver.find_element_by_xpath('.//li[@class="next"]//a').click()
        except NoSuchElementException:
            print("Scraping terminated before reaching target number of jobs. Needed {}, got {}.".format(num_jobs, len(jobs)))
            break

    return pd.DataFrame(jobs).reset_index()  #This line converts the dictionary object into a pandas DataFrame.


path = r'C:\chromedriver-win64\chromedriver-win64\chromedriver.exe'
df = get_jobs('data scientist', 1500, False, path, 4)

def init_driver(webdriver_path, headless=False):
    '''Initializes and returns a Chrome webdriver.'''
    options = webdriver.ChromeOptions()
    if headless:
        options.add_argument('headless')
    options.add_argument('user-agent=Your User Agent String Here')
    driver = webdriver.Chrome(executable_path=webdriver_path, options=options)
    driver.set_window_size(1120, 1000)
    return driver

def close_popups(driver):
    '''Closes popups on Glassdoor page if present.'''
    try:
        close_button = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, '[alt="Close"]'))
        )
        close_button.click()
        print('Popup closed.')
    except TimeoutException:
        print('No popup to close.')
        pass


def get_job_details(driver):
    '''Scrapes job details from the open job listing.'''
    try:
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, "employerName")))
        company_name = driver.find_element(By.CLASS_NAME, "employerName").text

        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, "location")))
        location = driver.find_element(By.CLASS_NAME, "location").text

        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.title")))
        job_title = driver.find_element(By.CSS_SELECTOR, "div.title").text

        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, "jobDescriptionContent")))
        job_description = driver.find_element(By.CLASS_NAME, "jobDescriptionContent").text

        return (company_name, location, job_title, job_description)
    except NoSuchElementException:
        return (None, None, None, None)
    
def scrape_jobs(driver, keyword, num_jobs):
    '''Main function to scrape job listings.'''
    jobs = []
    url = f"https://www.glassdoor.com/Job/jobs.htm?sc.keyword={keyword}"
    driver.get(url)

    while len(jobs) < num_jobs:
        close_popups(driver)

        job_buttons = driver.find_elements(By.CLASS_NAME, "jl")
        for job_button in job_buttons:
            if len(jobs) >= num_jobs:
                break
            try:
                job_button.click()
                job_details = get_job_details(driver)
                if job_details[0] is not None:
                    jobs.append(job_details)
            except Exception as e:
                print(f"Error collecting job details: {e}")

        try:
            next_button = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.CLASS_NAME, "next"))
            )
            next_button.click()
        except TimeoutException:
            print("No more pages or reached target number of jobs.")
            break

    return pd.DataFrame(jobs, columns=["Company Name", "Location", "Job Title", "Job Description"])

path = r'C:\chromedriver-win64\chromedriver-win64\chromedriver.exe'
driver = init_driver(path)
job_data = scrape_jobs(driver, "Data Scientist", 10)
print(job_data)




#error code 
#DevTools listening on ws://127.0.0.1:58620/devtools/browser/b336e10b-99c7-4e8d-a7c2-d31858b97d80
Traceback (most recent call last):
  File "c:\Users\LENOVO\Desktop\1.ESADE\cloud computing\assignment 3.py", line 209, in <module>
    df = get_jobs('data scientist', 1500, False, path, 4)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\LENOVO\Desktop\1.ESADE\cloud computing\assignment 3.py", line 48, in get_jobs
    WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CLASS_NAME, "selected"))).click()
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\selenium\webdriver\support\wait.py", line 105, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message:
Stacktrace:
        GetHandleVerifier [0x00007FF7DC214D02+56194]
        (No symbol) [0x00007FF7DC1804B2]
        (No symbol) [0x00007FF7DC0276AA]
        (No symbol) [0x00007FF7DC0716D0]
        (No symbol) [0x00007FF7DC0717EC]
        (No symbol) [0x00007FF7DC0B4D77]
        (No symbol) [0x00007FF7DC095EBF]
        (No symbol) [0x00007FF7DC0B2786]
        (No symbol) [0x00007FF7DC095C23]
        (No symbol) [0x00007FF7DC064A45]
        (No symbol) [0x00007FF7DC065AD4]
        GetHandleVerifier [0x00007FF7DC58D5BB+3695675]
        GetHandleVerifier [0x00007FF7DC5E6197+4059159]
        GetHandleVerifier [0x00007FF7DC5DDF63+4025827]
        GetHandleVerifier [0x00007FF7DC2AF029+687785]
        (No symbol) [0x00007FF7DC18B508]
        (No symbol) [0x00007FF7DC187564]
        (No symbol) [0x00007FF7DC1876E9]
        (No symbol) [0x00007FF7DC178094]
        BaseThreadInitThunk [0x00007FFF22AC53E0+16]
        RtlUserThreadStart [0x00007FFF236C485B+43]
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
